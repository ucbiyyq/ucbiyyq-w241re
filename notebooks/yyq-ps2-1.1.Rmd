---
title: "Problem Set 2"
output: html_notebook
---


```{r load_library}
library(tidyverse)
library(assertthat)
library(here)
```

```{r set_random_seed}
set.seed(232354)
```


# 1. FE Excercise 3.6

The Clingingsmith, Khwaja, and Kremer study discussed in section 3.5 may be be used to test the sharp null hypothesis that winning the visa lottery for the pilgrimage to Mecca had no effect on the views of Pakistani Muslims toward people from other countries. Assume that the Pakistani authorities assigned visas using complete random assignment.


```{r}
# for scope control
q01 <- list()

q01$data <- read_csv(here::here("data", "raw", "ps2", "Clingingsmith.2009.csv")) %>% 
    rowid_to_column("ID")
```

Each row of data represents a single respondent. The view_xyz fields are the changes in the views of the respondent towards peoples from other countries.

```{r}
q01$data %>% head()

# checks that we loaded the right csv
assert_that(q01$data %>% nrow() == 958)

# checks that the views columns is the rowSum of the other views columns
temp <- q01$data %>% 
    select(starts_with("views_")) %>% 
    rowSums()
assert_that(
    (temp == q01$data$views) %>% unique() == TRUE
)
```


## 1.a.

Conduct 10,000 simulated random assignments under the sharp null hypothesis

Under sharp null hypothesis, we can assume that the assignment to treatment has zero treatment effect on any of the units of treatment. So, we don't have to change the values of the views in either the potential outcome to treatment, D==1, or the potential outcome to control, D==0.

We are using simple random assignment, so basically flipping a fair coin to determine if a respondent is assigned to treatment (got visa) or control (did not get visa).

Note, we are calculating the ATE for every view. 


```{r}
# when given the clsm data, calculates the ATE for every view
q01_calc_ates <- function (dt) {
    dt <- dt %>% 
        select(success, starts_with("view")) %>% 
        group_by(success) %>% 
        summarize_all(list(mean))

    dt <- dt %>% 
        gather(starts_with("views"), key = "vw", value = "val") %>% 
        spread(key = success, value = val)
    
    dt <- dt %>% 
        mutate(ate = `1` - `0`) %>% 
        select(vw, ate)
    
    return(dt)
}
q01$ates <- q01_calc_ates(q01$data)
```


```{r}
# given the clsm data, runs n number of simulations
q01_sim_n <- function(dt, n) {
    
    # helper function to sim assignment to treatment by simple random assignment
    simpl_rand_assign <- function (xt) {
        # simple random assignment to treatment or control. R
        # Reuses the view variable because that is the treatment indicator variable expected by the q01_calc_ates function
        xt <- xt %>% 
            select(starts_with("view")) %>% 
            mutate(success = rbinom(nrow(xt),1,.5))
        return(xt)
    }
    
    # creates a nested table of clsm data, one row per sim    
    dt <- dt %>% 
        select(success, starts_with("views"))
    
    sims <- seq(1,n,1) %>% 
        tibble() %>% 
        set_names(nm = "sim_id")
    
    sims <- sims %>% 
        crossing(dt) %>%
        group_by(sim_id) %>% 
        nest(.key="sim_data")
    
    # runs each sim data through simple random assignments
    sims <- sims %>% 
        mutate(sim_data = map(sim_data, simpl_rand_assign))
    
    # runs each sim data through the ate calculations
    sims <- sims %>%
        mutate(sim_ates = map(sim_data, q01_calc_ates))
    
    return(sims)
}
```



```{r run_simulations}
# unnests table of ATEs for each view and sim_id
q01$sim_ates <- q01$data %>% 
    q01_sim_n(1000) %>% 
    select(sim_id, sim_ates) %>% 
    unnest()
```


```{r}
# checks that each simulation has the same number of ATEs as the actual ATEs
assert_that(
    q01$sim_ates %>% count(sim_id) %>% .$n %>% unique() == q01$ates %>% nrow()
)
```


```{r calc_ates_gte}
# given simulated and actual ATEs, calculates where 
# the simulated ATE is greater than or equal to the actual ATE, 
# and the absolute value of the simulated ATE is greater than or equal to the absoluate value of the actual ATE
# for every view-ATE
q01$res <- inner_join(q01$ates, q01$sim_ates, by = "vw", suffix = c("_actual", "_sim")) %>%
        mutate(
            gte = (ate_sim >= ate_actual)
            , gte_abs = (abs(ate_sim) >= abs(ate_actual)) 
        ) %>% 
        select(vw, sim_id, ate_sim, ate_actual, gte, gte_abs) %>% 
        arrange(vw, sim_id)
```


```{r plots_ates}
# visual aid to see what the sampling distribution of the sims are like, vs the actual ATE
q01$res %>% 
    ggplot(mapping = aes(x = ate_sim)) +
    geom_histogram(binwidth = 0.025) +
    geom_vline(mapping = aes(xintercept = ate_actual), color = "red", size = 1) +
    facet_wrap(vars(vw))+
    labs(
        title = "Actual ATE of Views is very different vs Simulated ATEs under sharp-null"
        , subtitle = "but some of the sub categories not so clear"
        , caption = "Data from PS2, Clingingsmith.2009.csv"
        , x = "Simulated ATEs"
        , y = "Number of Simulations"
    )
```


```{r}
# counts the gte, abs gte, and the implied p-values
q01_count_gte <- function (dt) {
    res_ttl <- dt %>% 
        count(vw) %>% 
        rename("num_sims" = n)
    
    res_gte <- dt %>% 
        count(vw, gte) %>% 
        spread(key = gte, value = n, fill = 0) %>% 
        rename("sim_gte_actual" = `TRUE`, "sim_lt_actual" = `FALSE`) 
    
    res_gte_abs <- dt %>% 
        count(vw, gte_abs) %>% 
        spread(key = gte_abs, value = n, fill = 0) %>%
        rename("sim_abs_gte_actual_abs" = `TRUE`, "sim_abs_lt_actual_abs" = `FALSE`)
    
    res <- plyr::join_all(list(res_ttl, res_gte, res_gte_abs), by="vw")
    
    res <- res %>% 
        mutate(
            p_val_ot = (sim_gte_actual / num_sims)
            , p_val_tt = (sim_abs_gte_actual_abs / num_sims)
        ) %>% 
        select(vw, num_sims, sim_gte_actual, p_val_ot, sim_abs_gte_actual_abs, p_val_tt)
    
    return(res)
}
q01$res_counts <- q01_count_gte(q01$res)
```


## 1.b. 

How many of the simulated random assignments generate an estimated ATE that is at least as large as
the actual estimate of the ATE?


**For aggregated Views, after `r q01$res_counts$num_sims %>% unique()` sims, about `r q01$res_counts %>% filter(vw == "views") %>% pull(sim_gte_actual)`**

## 1.c.

What is the implied one-tailed p-value?

**For aggregated Views, after `r q01$res_counts$num_sims %>% unique()` sims, implied one-tailed p-value is about `r q01$res_counts %>% filter(vw == "views") %>% pull(p_val_ot)`**


## 1.d.

How many of the simulated random assignments generate an estimated ATE that is at least as large in
absolute value as the actual estimate of the ATE?

**For aggregated Views, after `r q01$res_counts$num_sims %>% unique()` sims, about `r q01$res_counts %>% filter(vw == "views") %>% pull(sim_abs_gte_actual_abs)`**


## 1.e.

What is the implied two-tailed p-value?

**For aggregated Views, after `r q01$res_counts$num_sims %>% unique()` sims, implied two-tailed p-value is about `r q01$res_counts %>% filter(vw == "views") %>% pull(p_val_tt)`**



\newpage

# 2. FE exercise 3.8

Naturally occurring experiments sometimes involve what is, in effect, block random assignment. For example, Titunik studies the effect of lotteries that determine whether state senators in TX and AR serve two-year or four-year terms in the aftermath of decennial redistricting. These lotteries are conducted within each state, and so there are effectively two distinct experiments on the effects of term length. An interesting outcome variable is the number of bills (legislative proposals) that each senator introduces during a legislative session. The table below lists the number of bills introduced by senators in both states during 2003.



```{r}


```



