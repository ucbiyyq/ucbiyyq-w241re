---
title: "Problem Set 2"
output: html_notebook
---


```{r load_library}
library(tidyverse)
library(assertthat)
library(here)
```

```{r set_random_seed}
set.seed(232354)
```


# 1. FE Excercise 3.6

The Clingingsmith, Khwaja, and Kremer study discussed in section 3.5 may be be used to test the sharp null hypothesis that winning the visa lottery for the pilgrimage to Mecca had no effect on the views of Pakistani Muslims toward people from other countries. Assume that the Pakistani authorities assigned visas using complete random assignment.


```{r}
# for scope control
q01 <- list()

q01$data <- read_csv(here::here("data", "raw", "ps2", "Clingingsmith.2009.csv")) %>% 
    rowid_to_column("ID")
```

Each row of data represents a single respondent. The view_xyz fields are the changes in the views of the respondent towards peoples from other countries.

```{r}
q01$data %>% head()
```

```{r}
q01$data %>% str()
```

```{r}
q01$data %>% summary()
```

```{r}
# checks that we loaded the right csv
assert_that(q01$data %>% nrow() == 958)

# checks that the views columns is the rowSum of the other views columns
temp <- q01$data %>% 
    select(starts_with("views_")) %>% 
    rowSums()
assert_that(
    (temp == q01$data$views) %>% unique() == TRUE
)
```

```{r}
# quick viz to see if there's any large diff
q01$data %>% 
    select(-ID) %>% 
    gather(-success, key = "vw", value = "value") %>%
    mutate(success = as_factor(success)) %>% 
    ggplot(aes(x = value, fill = success)) +
    geom_histogram(binwidth = 1, alpha = 0.5, position = "identity") +
    facet_wrap(vars(vw)) +
    labs(title = "Distribution of views, if visa success, by target country", subtitle = "doesn't seem like there's a huge difference at first glance")

```


## 1.a.

Conduct 10,000 simulated random assignments under the sharp null hypothesis

Under sharp null hypothesis, we can assume that the assignment to treatment has zero treatment effect on any of the units of treatment. So, we don't have to change the values of the views in either the potential outcome to treatment, D==1, or the potential outcome to control, D==0.

We are using simple random assignment, so basically flipping a fair coin to determine if a respondent is assigned to treatment (got visa) or control (did not get visa).

Note, we are calculating the ATE for every view. 


```{r}
# when given the clsm data, calculates the ATE for every view
q01_calc_ates <- function (dt) {
    dt <- dt %>% 
        select(success, starts_with("view")) %>% 
        group_by(success) %>% 
        summarize_all(list(mean))

    dt <- dt %>% 
        gather(starts_with("views"), key = "vw", value = "val") %>% 
        spread(key = success, value = val)
    
    dt <- dt %>% 
        mutate(ate = `1` - `0`) %>% 
        select(vw, ate)
    
    return(dt)
}
q01$ates <- q01_calc_ates(q01$data)
```


```{r}
# given the clsm data, runs n number of simulations
q01_sim_n <- function(dt, n) {
    
    # helper function to sim assignment to treatment by simple random assignment
    simpl_rand_assign <- function (xt) {
        # simple random assignment to treatment or control. R
        # Reuses the view variable because that is the treatment indicator variable expected by the q01_calc_ates function
        xt <- xt %>% 
            select(starts_with("view")) %>% 
            mutate(success = rbinom(nrow(xt),1,.5))
        return(xt)
    }
    
    # creates a nested table of clsm data, one row per sim    
    dt <- dt %>% 
        select(success, starts_with("views"))
    
    sims <- seq(1,n,1) %>% 
        tibble() %>% 
        set_names(nm = "sim_id")
    
    sims <- sims %>% 
        crossing(dt) %>%
        group_by(sim_id) %>% 
        nest(.key="sim_data")
    
    # runs each sim data through simple random assignments
    sims <- sims %>% 
        mutate(sim_data = map(sim_data, simpl_rand_assign))
    
    # runs each sim data through the ate calculations
    sims <- sims %>%
        mutate(sim_ates = map(sim_data, q01_calc_ates))
    
    return(sims)
}
```



```{r q01_run_sims}
# unnests table of ATEs for each view and sim_id
q01$sim_ates <- q01$data %>% 
    q01_sim_n(1000) %>% 
    select(sim_id, sim_ates) %>% 
    unnest()
```


```{r}
# checks that each simulation has the same number of ATEs as the actual ATEs
assert_that(
    q01$sim_ates %>% count(sim_id) %>% .$n %>% unique() == q01$ates %>% nrow()
)
```


```{r calc_ates_gte}
# given simulated and actual ATEs, calculates where 
# the simulated ATE is greater than or equal to the actual ATE, 
# and the absolute value of the simulated ATE is greater than or equal to the absoluate value of the actual ATE
# for every view-ATE
q01$res <- inner_join(q01$ates, q01$sim_ates, by = "vw", suffix = c("_actual", "_sim")) %>%
        mutate(
            gte = (ate_sim >= ate_actual)
            , gte_abs = (abs(ate_sim) >= abs(ate_actual)) 
        ) %>% 
        select(vw, sim_id, ate_sim, ate_actual, gte, gte_abs) %>% 
        arrange(vw, sim_id)
```


```{r}
# visual aid to see what the sampling distribution of the sims are like, vs the actual ATE
q01$res %>% 
    ggplot(mapping = aes(x = ate_sim)) +
    geom_histogram(binwidth = 0.025) +
    geom_vline(mapping = aes(xintercept = ate_actual), color = "red", size = 1) +
    facet_wrap(vars(vw))+
    labs(
        title = "Actual ATE of Views is very different vs Simulated ATEs under sharp-null"
        , subtitle = "but some of the sub categories not so clear"
        , caption = "Data from PS2, Clingingsmith.2009.csv"
        , x = "Simulated ATEs"
        , y = "Number of Simulations"
    )
```


```{r}
# counts the gte, abs gte, and the implied p-values
q01_count_gte <- function (dt) {
    res_ttl <- dt %>% 
        count(vw) %>% 
        rename("num_sims" = n)
    
    res_gte <- dt %>% 
        count(vw, gte) %>% 
        spread(key = gte, value = n, fill = 0) %>% 
        rename("sim_gte_actual" = `TRUE`, "sim_lt_actual" = `FALSE`) 
    
    res_gte_abs <- dt %>% 
        count(vw, gte_abs) %>% 
        spread(key = gte_abs, value = n, fill = 0) %>%
        rename("sim_abs_gte_actual_abs" = `TRUE`, "sim_abs_lt_actual_abs" = `FALSE`)
    
    res <- plyr::join_all(list(res_ttl, res_gte, res_gte_abs), by="vw")
    
    res <- res %>% 
        mutate(
            p_val_ot = (sim_gte_actual / num_sims)
            , p_val_tt = (sim_abs_gte_actual_abs / num_sims)
        ) %>% 
        select(vw, num_sims, sim_gte_actual, p_val_ot, sim_abs_gte_actual_abs, p_val_tt)
    
    return(res)
}
q01$res_counts <- q01_count_gte(q01$res)
```


## 1.b. 

How many of the simulated random assignments generate an estimated ATE that is at least as large as
the actual estimate of the ATE?


**For aggregated Views, after `r q01$res_counts$num_sims %>% unique()` sims, about `r q01$res_counts %>% filter(vw == "views") %>% pull(sim_gte_actual)`**

## 1.c.

What is the implied one-tailed p-value?

**For aggregated Views, after `r q01$res_counts$num_sims %>% unique()` sims, implied one-tailed p-value is about `r q01$res_counts %>% filter(vw == "views") %>% pull(p_val_ot)`**


## 1.d.

How many of the simulated random assignments generate an estimated ATE that is at least as large in
absolute value as the actual estimate of the ATE?

**For aggregated Views, after `r q01$res_counts$num_sims %>% unique()` sims, about `r q01$res_counts %>% filter(vw == "views") %>% pull(sim_abs_gte_actual_abs)`**


## 1.e.

What is the implied two-tailed p-value?

**For aggregated Views, after `r q01$res_counts$num_sims %>% unique()` sims, implied two-tailed p-value is about `r q01$res_counts %>% filter(vw == "views") %>% pull(p_val_tt)`**



\newpage

# 2. FE exercise 3.8

Naturally occurring experiments sometimes involve what is, in effect, block random assignment. For example, Titunik studies the effect of lotteries that determine whether state senators in TX and AR serve two-year or four-year terms in the aftermath of decennial redistricting. These lotteries are conducted within each state, and so there are effectively two distinct experiments on the effects of term length. An interesting outcome variable is the number of bills (legislative proposals) that each senator introduces during a legislative session. The table below lists the number of bills introduced by senators in both states during 2003.

If you're interested, or would like more clarification, the published version of the paper is in the repository. 

```{r}
# for scope control
q02 <- list()

library(foreign)
q02$data <- foreign::read.dta(here::here("data", "raw", "ps2", "Titiunik.2010.dta"))
q02$data %>% head()
```

```{r}
q02$data %>% str()
```

```{r}
q02$data %>% summary()
```

```{r}
# checks how many records belong to each state
q02$data %>% count(texas0_arkansas1)
```

```{r}
# checks how many records belong to each term
q02$data %>% count(term2year)
```

```{r}
# checks how many records belong to each term and state
q02$data %>% count(term2year, texas0_arkansas1)
```

```{r}
# checks distribution of number of bills
q02$data %>% 
    ggplot(aes(bills_introduced)) +
    geom_histogram(binwidth = 10) +
    labs(title = "distribution of number of bills is right-skewed")
```


```{r}
# checks distribution of number of bills by term
q02$data %>% 
    ggplot(aes(bills_introduced)) +
    geom_histogram(binwidth = 10) +
    facet_wrap(vars(term2year), labeller = label_both) +
    labs(title = "looks about the same")
```


```{r}
# checks distribution of number of bills by state
q02$data %>% 
    ggplot(aes(bills_introduced)) +
    geom_histogram(binwidth = 10) +
    facet_wrap(vars(texas0_arkansas1), labeller = label_both) +
    labs(title = "Arkansas distribution is quite different from Texas")
```


```{r}
# checks distribution of number of bills by facets
q02$data %>% 
    mutate(term2year = as_factor(term2year)) %>% 
    ggplot(aes(bills_introduced, fill = term2year)) +
    geom_histogram(binwidth = 10, alpha = 0.5, position = "identity") +
    facet_wrap(vars(texas0_arkansas1), labeller = label_both) +
    labs(title = "Number of bills introduced by state, if term2year or not")
```


```{r}
# helper function to output multiple simulations
# assumes sharp-null hypothesis, that term2year makes no difference
q02_sim_n <- function(data, n = 10) {
    # helper function to output a single simulation run
    # uses simple random assignment with fair coin flip
    # calculates the ATE for each state
    calc_sim <- function(data) {
        res <- data %>% 
            mutate(term2year = rbinom(nrow(.), 1, .5)) %>% 
            group_by(texas0_arkansas1, term2year) %>% 
            summarize(bills_introduced = mean(bills_introduced)) %>% 
            ungroup() %>% 
            spread(bills_introduced, key = term2year) %>% 
            select(texas0_arkansas1, `1`, `0`) %>% 
            mutate(ate = floor(`1` - `0`)) %>% 
            select(texas0_arkansas1, ate)
            # spread(texas0_arkansas1, value = ate) %>% 
        return(res)
    }
    
    # runs n simulations of the ate
    sim_res <- list()
    for (i in 1:n) {
        sim_i <- calc_sim(data)
        sim_i$sim_id <- i
        sim_res[[i]] <- sim_i
    }
    
    # returns a dataframe
    sim_res <- sim_res %>% 
        bind_rows() %>%
        select(sim_id, texas0_arkansas1, ate) %>% 
        arrange(sim_id, texas0_arkansas1)
    return(sim_res)
}
# temp <- q02$data %>% q02_sim_n(n = 10)
```

```{r q02_rum_sims}
q02$sims <- q02$data %>% q02_sim_n(n = 1000)
```

```{r}
q02$sims %>% 
    mutate(texas0_arkansas1 = as_factor(texas0_arkansas1)) %>% 
    ggplot(aes(x = ate, fill = texas0_arkansas1)) +
    geom_histogram(binwidth = 5, position = "identity", alpha = 0.5) +
    labs(title = "distribution of ATEs based on simulations assuming sharp null")
```

```{r}
q02$sims %>% 
    spread(key = "texas0_arkansas1", value = "ate") %>% 
    summary()
```


## 2.a. 

For each state, estimate the effect of having a two-year term on the number of bills introduced. 

**for Texas, ATE of having a two-year term is about -17. For Arkansas, ATE is about -11. Assuming we're dealing with whole bills.**


```{r}
q02$data %>% 
    group_by(term2year, texas0_arkansas1) %>% 
    summarize(bills_introduced = mean(bills_introduced)) %>% 
    ungroup() %>% 
    spread(bills_introduced, key = term2year) %>% 
    select(texas0_arkansas1, `1`, `0`) %>% 
    mutate(ate = floor(`1` - `0`))
    
```


## 2.b.

For each state, estimate the standard error of the estimated ATE.

Note, we can't do this empirically, so we have to use the following formulas.



```{r}
q02$data
```



```{r}
q02_sim_n <- function(data, n = 10) {
    calc_sim <- function() {
        
    }
}
q02$data %>% q02_sim_n()
```

## 2.c.

Use equation (3.10) to estimate the overall ATE for both states combined. 

```{r}

```

## 2.d.

Explain why, in this study, simply pooling the data for the two states and comparing the average number of bills introduced by two-year senators to the average number of bills introduced by four-year senators leads to biased estimate of the overall ATE. 

## 2.e.

Insert the estimated standard errors into equation (3.12) to estimate the stand error for the overall ATE. 

```{r}

```

## 2.f.

Use randomization inference to test the sharp null hypothesis that the treatment effect is zero for senators in both states. 

```{r}

``` 

## 2.g.

**IN Addition:** Plot histograms for both the treatment and control groups in each state (for 4 histograms in total).


